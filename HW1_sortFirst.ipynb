{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgaqXBYJDx0D"
      },
      "source": [
        "#HW #1. Improve code Efficiency: Sort First!\n",
        "\n",
        "## Scenario.\n",
        "\n",
        "In a two class, classification problem, it is common to use a classifier that outputs confidences (rather than simply class labels). A good example of this is a Support Vector Machine. A pro for using such a classifier is that you gain more information -- specifically the confidence in the classification result. A con is that in order to make a final classification decision, a threshold value must be determined. For example, if a threshold of 0.75 is chosen, the class label 1 would be assigned for confidences greater than 0.75 and for confidences less than 0.75 a class label of 0 would be assigned. However, this begs the question: how is the threshold chosen?\n",
        "\n",
        "Many data scientists will choose a threshold based on the experimental results and/or operational constraints. In this code example, we assume that we have confidences and true labels for a large data set. To determine a good threshold we will compute the true positive rates (TPRs) and false positive rates (FPRs) at all relevant thresholds. The relevant thresholds are considered those that would change the TPRs and FPRs.\n",
        "\n",
        "In the code below, a function is defined to compute the TPR and FPR at all relevant thresholds. However, the code is not very efficient and can be improved. (Note there are tips and hints found in the comments.)\n",
        "\n",
        "Your task is the following:\n",
        "\n",
        "## Question 1\n",
        "**40 POINTS**  \n",
        "Assess the time complexity of the method computeAllTPRs(...). Provide a line-by-line assessment in comments identifying the proportional number of steps (bounding notation is sufficient) per line: eg, O(1), O(log n), O(n), etc. Also, derive a time step function T(n) for the entire method (where n is the size of input true_label).\n",
        "\n",
        "## Question 2\n",
        "**30 POINTS**  \n",
        "Implement a new function computeAllTPRs_improved(...) which performs the same task as computeAllTPRs but has a significantly reduced time complexity. Also provide a line-by-line assessment in comments identifying the proportional number of steps per line, and derive a time step function T(n) for the entire method (where n is the size of input true_label).\n",
        "\n",
        "## Question 3\n",
        "**30 POINTS**  \n",
        "Compare the theoretical time complexities of both methods and predict which is more efficient. Next, test your prediction by timing both methods on sample inputs of varying sizes. Create a plot of inputSize vs runtime (as done in similar class examples).  \n",
        "\n",
        "**NOTE: Do not include runtimes for graphing**\n",
        "\n",
        "**TOTAL POINTS: 100**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tQs8b3ccEskN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from copy import deepcopy\n",
        "from numpy import argmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4t6Gd-XNWdr"
      },
      "source": [
        "Answer Question #1 in the comments of the code chunk below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IFu90tkjEORa"
      },
      "outputs": [],
      "source": [
        "def computeAllTPRs(true_label, confs):\n",
        "        '''\n",
        "\n",
        "        inputs:\n",
        "         - true_label: list of labels, assumed to be 0 or 1 (a two class problem)\n",
        "         - confs: list of confidences\n",
        "\n",
        "        This method computes the True Positive Rate (TPRs) and FPRs for all relevant\n",
        "        thresholds given true_label and confs. Relevant thresholds are considered\n",
        "        all different values found in confs.\n",
        "        '''\n",
        "\n",
        "        # Define / initialize  variables\n",
        "        sentinelValue = -1 # used to replace max value found thus far # O(1)\n",
        "        totalPositives = sum(true_label) #O(1)\n",
        "        totalNegatives = len(true_label) - totalPositives #O(1) since true_labels is not variable in size\n",
        "        truePositives = 0 #O(1)\n",
        "        falsePositives = 0 #O(1)\n",
        "        # Hint: Consider Memory Management\n",
        "        truePositiveRate = [] #O(1)\n",
        "        falsePositiveRate = [] #O(1)\n",
        "\n",
        "        #Hint: Although not explicitly clear, the loop structure below is an\n",
        "            #embeded loop ie, O(n^2) ... do you see why??\n",
        "        #Hint: If you sort the confidences first you can improve the iteration scheme.\n",
        "\n",
        "        # Iterate over all relevant thresholds. Compute TPR and FPR for each and\n",
        "        # append to truePositiveRate , falsePositiveRate lists.\n",
        "\n",
        "        for i in range(len(confs)): #O(n)\n",
        "          maxVal = max(confs)  # O(n) since the max fuction interates over the list and finds the greatest valye\n",
        "          argMax = argmax(confs) #O(n) since it interates through and returns the index of the maximum element\n",
        "          confs[argMax] = sentinelValue #O(1)\n",
        "          if true_label[argMax]==1: #O(1)\n",
        "            truePositives += 1 #O(1)\n",
        "          else:\n",
        "            falsePositives += 1 #O(1)\n",
        "\n",
        "          truePositiveRate.append(truePositives/totalPositives) #O(1)\n",
        "          falsePositiveRate.append(falsePositives/totalNegatives) #O(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6RBVDmTOeysa"
      },
      "outputs": [],
      "source": [
        "def testComputeAllTPRs(numSamples):\n",
        "\n",
        "  confList = [] #O(1)\n",
        "  labels = []  #O(1)\n",
        "  maxVal = 10000 #O(1)\n",
        "  for i in range(0,numSamples): #O(n)\n",
        "    n = random.randint(1,maxVal) # O(logn)\n",
        "    confList.append(n/maxVal) # O(1)\n",
        "    if n/maxVal > .5: #O(1)\n",
        "      lab = 1 #O(1)\n",
        "    else:\n",
        "      lab = 0 #O(1)\n",
        "    labels.append(lab) # O(1)\n",
        "  computeAllTPRs(labels, deepcopy(confList))  # Why a deepcopy here? # The time complexity of the above funciton is O(n^2), would this be the case?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0aNsuFFMzLt"
      },
      "source": [
        "#### Question 2:\n",
        "Below, provide your implementation for Question #2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I4SoYMYBMyzA"
      },
      "outputs": [],
      "source": [
        "def computeAllTPRs_improve(true_label, confs):\n",
        "    '''\n",
        "    inputs:\n",
        "     - true_label: list of labels, assumed to be 0 or 1 (a two-class problem)\n",
        "     - confs: list of confidences\n",
        "     \n",
        "    This method computes the True Positive Rate (TPRs) and False Positive Rates (FPRs) \n",
        "    for all relevant thresholds given true_label and confs.\n",
        "    '''\n",
        "    #Total positives and negatives\n",
        "    totalPositives = sum(true_label) #O(1) # all the 1's added up in true labels\n",
        "    totalNegatives = len(true_label) - totalPositives #O(1) since true_labels is not variable in size # the length of that list minus the total number of 1's which is total number of 0's in the list\n",
        "        \n",
        "    #Initialize counters for TPR and FPR\n",
        "    truePositives = 0 #O(1)\n",
        "    falsePositives = 0 #O(1)\n",
        "    \n",
        "    #Lists to store TPRs and FPRs at each threshold\n",
        "    # Hint: Consider Memory Management\n",
        "    truePositiveRate = [] #O(1)\n",
        "    falsePositiveRate = [] #O(1)\n",
        "\n",
        "    # taking the lists and zipping them together: so each element in true_label is associated with each element in conf like: [(0.3,1,(0.9,1),(0.7,0), etc]\n",
        "    combined=list(zip(confs, true_label)) # O(n)\n",
        "    # sort the tuples by the confidence level (sorted function does by the first item in the tuple), now looks like [(0.3,1),(0.7,0),(0.9,1) etc]\n",
        "    comb_sorted=sorted(combined) #O(n)\n",
        "\n",
        "\n",
        "    # for each tuple pair in the sorted list of tuples, if the label is 1, add to the TP if not add to FP, and at each iteration, add the rates to the lists\n",
        "    for c,l in comb_sorted: #O(n) \n",
        "        if l==1: #O(1)\n",
        "            truePositives += 1 #O(1)\n",
        "        else:\n",
        "            falsePositives += 1 #O(1)\n",
        "\n",
        "        #at each iteration, add the true pos and true neg rates to the lists keeping track, to avoid division by zero, check that first\n",
        "        if totalPositives!=0:\n",
        "            truePositiveRate.append(truePositives/totalPositives) #O(1) # for each iteration, add\n",
        "        else:\n",
        "            skip\n",
        "        if totalNegatives!=0:\n",
        "            falsePositiveRate.append(falsePositives/totalNegatives) #O(1)\n",
        "        else:\n",
        "            skip\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0.3, 0), (0.6, 1), (0.7, 1), (0.4, 1), (0.5, 0), (0.8, 0), (0.2, 1), (0.9, 0)]\n",
            "[(0.2, 1), (0.3, 0), (0.4, 1), (0.5, 0), (0.6, 1), (0.7, 1), (0.8, 0), (0.9, 0)]\n"
          ]
        }
      ],
      "source": [
        "# SCRATCH WORK to see my process:\n",
        "# testing out some things for problem 2:\n",
        "# associated the values\n",
        "true_labels=[0,1,1,1,0,0,1,0]\n",
        "conf=[0.3,0.6,0.7,0.4,0.5, 0.8,0.2,0.9]\n",
        "combined=list(zip(conf, true_labels))\n",
        "print(combined)\n",
        "comb_sorted=sorted(combined)\n",
        "print(comb_sorted)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP72j3GqM6AH"
      },
      "source": [
        "### Question #3. \n",
        "Below, provide your code which records and plots the runtime for the original and improved methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the theoretical time complexities of both methods and predict which is more efficient. Next, test your prediction by timing both methods on sample inputs of varying sizes. Create a plot of inputSize vs runtime (as done in similar class examples). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PAWM8pogeysb"
      },
      "outputs": [],
      "source": [
        "# similar to the plot in 5012_listsAreDynamicArrays ipynb provided:\n",
        "'''\n",
        "main method: run trial for different inputs sizes n\n",
        "'''\n",
        "maxN = 100000  # max insertions to list to set termination condition\n",
        "n = 2  # initialize number of insertions \n",
        "x,y_dyn,y_stat = list(), list(),list()\n",
        "while n <= maxN:   \n",
        "  x.append(n)\n",
        "  y_dyn.append(compute_dynamic(n))\n",
        "  y_stat.append(compute_static(n))\n",
        "  n += 100\n",
        " \n",
        "# display results\n",
        "plt.plot(x, y_dyn, label = 'Dynamic') \n",
        "plt.plot(x, y_stat, label = 'Static') \n",
        "plt.legend(frameon = 'none')\n",
        "plt.title('Runtime Analysis')\n",
        "plt.xlabel('size of input (proportional)')\n",
        "plt.ylabel('run time')\n",
        "plt.show() \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Plots:\n",
        "\n",
        "# display results\n",
        "plt.plot(x, original, label = 'Original') \n",
        "plt.plot(x, improved, label = 'Improved') \n",
        "plt.legend(frameon = 'none')\n",
        "plt.title('Runtime Analysis')\n",
        "plt.xlabel('size of input (proportional)') #???????????????\n",
        "plt.ylabel('run time')\n",
        "plt.show() \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
